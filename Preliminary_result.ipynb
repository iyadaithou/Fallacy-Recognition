{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iyadaithou/Fallacy-Recognition/blob/main/Preliminary_result.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers spacy\n",
        "!python -m spacy download en_core_web_md\n",
        "!pip install sentence-transformers\n"
      ],
      "metadata": {
        "id": "wtwR9Pien5Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "zPSY2wHyoy_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ad1f6d5-adac-42c9-92c2-7fd7e907a1dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"tasksource/logical-fallacy\")\n",
        "# Print the structure of the dataset\n",
        "print(dataset)\n",
        "\n",
        "# Access a specific split\n",
        "train_dataset = dataset['train']\n",
        "\n",
        "# Print the first few examples from the training set\n",
        "print(train_dataset[:5])"
      ],
      "metadata": {
        "id": "waZLI_8Hovp-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0107e390-b7bd-4c0c-c97e-a3915b2ef72f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['config', 'source_article', 'logical_fallacies'],\n",
            "        num_rows: 2680\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['config', 'source_article', 'logical_fallacies'],\n",
            "        num_rows: 511\n",
            "    })\n",
            "    dev: Dataset({\n",
            "        features: ['config', 'source_article', 'logical_fallacies'],\n",
            "        num_rows: 570\n",
            "    })\n",
            "})\n",
            "{'config': ['edu', 'edu', 'edu', 'edu', 'edu'], 'source_article': ['company\\'s slogan \"Expect More. Pay Less.\"', \"The bigger a child's shoe size, the better the child's handwriting\", 'Since many people believe this, then it must be true', \"Senator Randall isn't lying when she says she cares about her constituentsâ€”she wouldn't lie to people she cares about.\", 'A mother is telling her daughter that she went over her data for the month, and the daughter begins telling her mother about getting an A on a math test.'], 'logical_fallacies': ['appeal to emotion', 'false causality', 'ad populum', 'circular reasoning', 'fallacy of relevance']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Step 1 & 2: Data is already split\n",
        "\n",
        "# Prepare the data (assuming dataset is already loaded)\n",
        "train_texts = dataset['train']['source_article']\n",
        "train_labels = dataset['train']['logical_fallacies']\n",
        "dev_texts = dataset['dev']['source_article']\n",
        "dev_labels = dataset['dev']['logical_fallacies']\n",
        "test_texts = dataset['test']['source_article']\n",
        "test_labels = dataset['test']['logical_fallacies']\n",
        "\n",
        "# Step 4: Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "dev_labels_encoded = label_encoder.transform(dev_labels)\n",
        "test_labels_encoded = label_encoder.transform(test_labels)\n",
        "\n",
        "# Step 3 & 5: Create a pipeline with TF-IDF and Logistic Regression\n",
        "model = make_pipeline(TfidfVectorizer(lowercase=True, stop_words='english'), LogisticRegression(max_iter=1000))\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_texts, train_labels_encoded)\n",
        "\n",
        "# Step 6: Evaluate the model\n",
        "dev_predictions = model.predict(dev_texts)\n",
        "print(\"Validation Set Performance:\")\n",
        "print(classification_report(dev_labels_encoded, dev_predictions, target_names=label_encoder.classes_))\n",
        "\n",
        "# Finally, evaluate on the test set\n",
        "test_predictions = model.predict(test_texts)\n",
        "print(\"Test Set Performance:\")\n",
        "print(classification_report(test_labels_encoded, test_predictions, target_names=label_encoder.classes_))\n",
        "\n",
        "\n",
        "# Define a function to calculate metrics and return them in a dictionary\n",
        "def calculate_metrics(y_true, y_pred, average_type='weighted'):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=average_type)\n",
        "    return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1}\n",
        "\n",
        "# Calculate metrics for the test set\n",
        "test_metrics = calculate_metrics(test_labels_encoded, test_predictions)\n",
        "\n",
        "# Add the metrics to a new dataframe row\n",
        "results_df = pd.DataFrame([test_metrics], index=['Logistic Regression'])\n",
        "\n",
        "# Display the dataframe\n",
        "print(results_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ghpfN6fDxPD",
        "outputId": "95c89f0b-ea2b-4e13-e8ca-93ca47755980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Set Performance:\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "            ad hominem       0.42      0.46      0.44        52\n",
            "            ad populum       0.50      0.29      0.37        51\n",
            "     appeal to emotion       0.36      0.21      0.27        42\n",
            "    circular reasoning       0.67      0.33      0.44        18\n",
            "          equivocation       0.00      0.00      0.00         9\n",
            "fallacy of credibility       0.38      0.12      0.18        26\n",
            "  fallacy of extension       0.50      0.07      0.13        40\n",
            "      fallacy of logic       0.00      0.00      0.00        33\n",
            "  fallacy of relevance       0.83      0.11      0.20        44\n",
            "       false causality       0.47      0.19      0.27        43\n",
            "         false dilemma       0.71      0.17      0.28        29\n",
            " faulty generalization       0.28      0.67      0.39        84\n",
            "           intentional       0.31      0.64      0.42        99\n",
            "\n",
            "              accuracy                           0.35       570\n",
            "             macro avg       0.42      0.25      0.26       570\n",
            "          weighted avg       0.41      0.35      0.30       570\n",
            "\n",
            "Test Set Performance:\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "            ad hominem       0.43      0.53      0.48        57\n",
            "            ad populum       0.65      0.43      0.52        35\n",
            "     appeal to emotion       0.43      0.12      0.19        49\n",
            "    circular reasoning       0.33      0.10      0.15        20\n",
            "          equivocation       0.00      0.00      0.00         9\n",
            "fallacy of credibility       0.62      0.14      0.22        37\n",
            "  fallacy of extension       0.88      0.27      0.41        26\n",
            "      fallacy of logic       1.00      0.03      0.06        31\n",
            "  fallacy of relevance       0.71      0.11      0.19        46\n",
            "       false causality       0.52      0.32      0.40        34\n",
            "         false dilemma       0.33      0.11      0.17        18\n",
            " faulty generalization       0.27      0.63      0.38        89\n",
            "           intentional       0.26      0.62      0.37        60\n",
            "\n",
            "              accuracy                           0.35       511\n",
            "             macro avg       0.50      0.26      0.27       511\n",
            "          weighted avg       0.49      0.35      0.31       511\n",
            "\n",
            "                     Accuracy  Precision   Recall  F1 Score\n",
            "Logistic Regression   0.34638   0.486567  0.34638  0.312258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "!pip install accelerate -U\n",
        "!pip install transformers[torch] -U\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"tasksource/logical-fallacy\")\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Tokenize the input (this will take care of padding/truncation)\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['source_article'], padding='max_length', truncation=True, max_length=512)\n",
        "\n",
        "# Apply the tokenizer to the dataset\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "# Fit the label encoder using the logical fallacies labels from the train split\n",
        "label_encoder.fit(dataset['train']['logical_fallacies'])\n",
        "# Create a dictionary that maps each label to an integer\n",
        "label2id = {label: id for id, label in enumerate(label_encoder.classes_)}\n",
        "# Create a dictionary that maps each integer to its corresponding label\n",
        "id2label = {id: label for label, id in label2id.items()}\n",
        "\n",
        "# Function to encode labels\n",
        "def encode_labels(example):\n",
        "    example['labels'] = label2id[example['logical_fallacies']]\n",
        "    return example\n",
        "\n",
        "# Encode the labels in all datasets\n",
        "tokenized_datasets = tokenized_datasets.map(encode_labels)\n",
        "\n",
        "# Load the model\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(label2id))\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    evaluation_strategy='epoch',\n",
        ")\n",
        "\n",
        "# Function to compute metrics for evaluation\n",
        "def compute_metrics(p):\n",
        "    predictions = np.argmax(p.predictions, axis=1)\n",
        "    labels = p.label_ids\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['dev'],\n",
        "    compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model\n",
        "test_results = trainer.evaluate(tokenized_datasets['test'])\n",
        "\n",
        "# Convert the results to a pandas dataframe\n",
        "results_df = pd.DataFrame([test_results], index=['DistilBERT Model'])\n",
        "results_df = results_df.drop(columns=['eval_loss', 'epoch'])\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOI3v8xiNwcC",
        "outputId": "76f16053-fc2b-4a5d-d0bf-ceed9b19fe59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.26.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.11 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.26.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.11->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.11->transformers[torch]) (1.3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "\n",
        "# Evaluate the model\n",
        "test_results = trainer.evaluate(tokenized_datasets['test'])\n",
        "\n",
        "# Convert the results to a pandas dataframe\n",
        "results_df = pd.DataFrame([test_results], index=['DistilBERT Model'])\n",
        "results_df = results_df.drop(columns=['eval_loss', 'epoch'])\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "Ioqd3vcEPXBv",
        "outputId": "2404ae91-1a4a-4de5-db0e-21bc9ec1c354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='504' max='504' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [504/504 36:50, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.345141</td>\n",
              "      <td>0.249123</td>\n",
              "      <td>0.143465</td>\n",
              "      <td>0.113262</td>\n",
              "      <td>0.249123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.960727</td>\n",
              "      <td>0.394737</td>\n",
              "      <td>0.358174</td>\n",
              "      <td>0.513196</td>\n",
              "      <td>0.394737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.091700</td>\n",
              "      <td>1.750834</td>\n",
              "      <td>0.438596</td>\n",
              "      <td>0.429805</td>\n",
              "      <td>0.459586</td>\n",
              "      <td>0.438596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [64/64 00:31]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  eval_accuracy   eval_f1  eval_precision  eval_recall  \\\n",
            "DistilBERT Model       0.399217  0.397622        0.447941     0.399217   \n",
            "\n",
            "                  eval_runtime  eval_samples_per_second  eval_steps_per_second  \n",
            "DistilBERT Model       31.7317                   16.104                  2.017  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# Load models\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Define amplifiers with assigned strength\n",
        "amplifiers = {\"some\": 1, \"a few\": 1, \"several\": 2, \"many\": 3, \"most\": 4, \"all\": 5, \"every\": 5, \"always\": 5}\n",
        "\n",
        "def calculate_semantic_similarity(sentence1, sentence2):\n",
        "    inputs1 = tokenizer(sentence1, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    inputs2 = tokenizer(sentence2, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs1 = model(**inputs1)\n",
        "        outputs2 = model(**inputs2)\n",
        "    sentence_embedding1 = outputs1.last_hidden_state.mean(dim=1)\n",
        "    sentence_embedding2 = outputs2.last_hidden_state.mean(dim=1)\n",
        "    cosine_sim = torch.nn.functional.cosine_similarity(sentence_embedding1, sentence_embedding2)\n",
        "    return cosine_sim.item()\n",
        "\n",
        "def detect_amplifier_strength(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    strength = 0\n",
        "    for token in doc:\n",
        "        for amp, val in amplifiers.items():\n",
        "            if amp in token.text:\n",
        "                strength = max(strength, val)\n",
        "    return strength\n",
        "\n",
        "def amplification_factor(sentence1, sentence2):\n",
        "    semantic_similarity = calculate_semantic_similarity(sentence1, sentence2)\n",
        "    # If the sentences are identical, set amplification factor to 0\n",
        "    if semantic_similarity == 1:\n",
        "        return 0\n",
        "\n",
        "    strength1 = detect_amplifier_strength(sentence1)\n",
        "    strength2 = detect_amplifier_strength(sentence2)\n",
        "\n",
        "    # Calculate the amplification factor based on the presence and change in amplifier strength\n",
        "    if strength2 > strength1:\n",
        "        # Normalize the change in strength to a scale of 0 to 1\n",
        "        change_in_strength = (strength2 - strength1) / max(amplifiers.values())\n",
        "        # Factor in semantic similarity to ensure relevance\n",
        "        factor = min(change_in_strength * semantic_similarity, 1.0)\n",
        "    else:\n",
        "        # No amplification or semantic relevance\n",
        "        factor = semantic_similarity * 0.1  # Slight adjustment to account for some relevance\n",
        "\n",
        "    return factor\n",
        "\n",
        "# Example usage\n",
        "sentence1 = \"Some students passed the exam.\"\n",
        "sentence2 = \"Some students passed all the exams.\"\n",
        "print(\"Amplification Factor:\", amplification_factor(sentence1, sentence2))\n",
        "\n",
        "sentence1 = \"All students passed the exam.\"\n",
        "sentence2 = \"some students passed the exam.\"\n",
        "print(\"Amplification Factor:\", amplification_factor(sentence1, sentence2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDiYQEP4t4ph",
        "outputId": "47056484-d7f5-4371-e3d1-106f4af07afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amplification Factor: 0.9350095987319946\n",
            "Amplification Factor: 0.1872041463851929\n"
          ]
        }
      ]
    }
  ]
}